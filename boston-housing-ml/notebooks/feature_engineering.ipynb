{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering for Boston Housing Dataset\n",
    "\n",
    "In this notebook, we will apply various feature engineering techniques to the Boston Housing dataset to improve the performance of our machine learning models. We will explore the following steps:\n",
    "\n",
    "1. Loading the dataset\n",
    "2. Handling missing values\n",
    "3. Creating new features\n",
    "4. Encoding categorical variables\n",
    "5. Scaling features\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('../data/boston_housing.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "missing_values[missing_values > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data['column_name'] = imputer.fit_transform(data[['column_name']])  # Replace 'column_name' with actual column\n",
    "\n",
    "# Create new features\n",
    "data['new_feature'] = data['feature1'] / data['feature2']  # Example of creating a new feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical variables\n",
    "categorical_features = ['categorical_column']  # Replace with actual categorical columns\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "data_encoded = one_hot_encoder.fit_transform(data[categorical_features]).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['numerical_column1', 'numerical_column2']  # Replace with actual numerical columns\n",
    "data[numerical_features] = scaler.fit_transform(data[numerical_features])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we have performed feature engineering on the Boston Housing dataset. We handled missing values, created new features, encoded categorical variables, and scaled numerical features. These steps are crucial for improving the performance of our machine learning models. Next, we can proceed to model training and evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}